model_path: "../../models/hf_models/Llama-3.3-70B-Instruct-GGUF/Llama-3.3-70B-Instruct-Q4_K_M.gguf"
max_seq_length: 128000
max_new_tokens: 4096
seed: None
temperature: 0.6
top_k: 256
min_p: 0.00
top_p: 0.95
n_gpu_layers: 81
chat_format: "llama-3"
repetition_penalty: 1.0
